#!/usr/bin/env python3
"""
Real-world example: AI coding assistant that uses hybrid file operations
to work with different AI frameworks simultaneously.
"""

import asyncio
import tempfile
import json
from pathlib import Path

from aida.tools.files import FileOperationsTool


class AICodeAssistant:
    """
    Example AI coding assistant that demonstrates hybrid file operations
    in a realistic scenario.
    """
    
    def __init__(self):
        self.file_tool = FileOperationsTool()
        
        # Enable all hybrid features
        self.pydantic_tools = self.file_tool.to_pydantic_tools()
        self.mcp_server = self.file_tool.get_mcp_server()
        self.observability = self.file_tool.enable_observability({
            "enabled": True,
            "service_name": "ai-code-assistant"
        })
    
    async def process_project_with_aida(self, project_dir: str):
        """Use original AIDA interface for internal project analysis."""
        print("üîß AIDA INTERFACE: Project Analysis")
        print("-" * 40)
        
        # Analyze project structure using rich AIDA metadata
        result = await self.file_tool.execute(
            operation="list_files",
            path=project_dir,
            pattern="*.py",
            recursive=True
        )
        
        python_files = result.result['files']
        print(f"üìä Analysis Results:")
        print(f"   - Found {len(python_files)} Python files")
        print(f"   - Total directory: {result.result['path']}")
        print(f"   - Execution time: {result.duration_seconds}s")
        print(f"   - Tool metadata: {result.metadata}")
        
        return python_files
    
    async def generate_docs_with_pydantic(self, files: list, output_dir: str):
        """Use PydanticAI interface for clean, typed operations."""
        print("\nü§ñ PYDANTIC AI INTERFACE: Documentation Generation")
        print("-" * 40)
        
        docs_dir = Path(output_dir) / "docs"
        await self.pydantic_tools["create_directory"](str(docs_dir))
        
        for file_info in files[:2]:  # Process first 2 files for demo
            # Read source file
            content = await self.pydantic_tools["read_file"](file_info['path'])
            
            # Generate documentation (simplified)
            doc_content = f"""# Documentation for {file_info['name']}

**File:** {file_info['path']}
**Size:** {content['size_bytes']} bytes
**Lines:** {content['line_count']} lines

## Content Preview
```python
{content['content'][:200]}...
```

Generated by AI Code Assistant
"""
            
            # Write documentation
            doc_file = docs_dir / f"{Path(file_info['name']).stem}_docs.md"
            result = await self.pydantic_tools["write_file"](
                str(doc_file), 
                doc_content
            )
            
            print(f"üìù Generated docs for {file_info['name']}: {result['bytes_written']} bytes")
    
    async def integrate_with_external_via_mcp(self, project_dir: str):
        """Use MCP interface for external system integration."""
        print("\nüåê MCP INTERFACE: External Integration")
        print("-" * 40)
        
        # Create project manifest for external systems (like Claude)
        manifest = {
            "project_name": Path(project_dir).name,
            "analysis_timestamp": "2025-01-01T00:00:00Z",
            "file_operations_version": "2.0.0",
            "capabilities": ["read", "write", "analyze"]
        }
        
        manifest_file = Path(project_dir) / "project_manifest.json"
        
        # Use MCP interface (as external systems would)
        result = await self.mcp_server.call_tool("file_write_file", {
            "path": str(manifest_file),
            "content": json.dumps(manifest, indent=2)
        })
        
        if not result.get('isError'):
            print("‚úÖ Project manifest created for external systems")
            
            # Verify using MCP read
            read_result = await self.mcp_server.call_tool("file_read_file", {
                "path": str(manifest_file)
            })
            
            if not read_result.get('isError'):
                manifest_data = json.loads(read_result['content'][0]['text'])
                parsed_manifest = json.loads(manifest_data['content'])
                print(f"   Project: {parsed_manifest['project_name']}")
                print(f"   Capabilities: {parsed_manifest['capabilities']}")
        else:
            print("‚ùå Failed to create manifest")
    
    async def demonstrate_observability(self):
        """Show observability in action."""
        print("\nüìä OBSERVABILITY: Tracing Operations")
        print("-" * 40)
        
        if self.observability.enabled:
            # Create a traced operation
            with self.observability.trace_operation("demo_trace", path="/demo/path"):
                # Simulate some work
                await asyncio.sleep(0.001)
                print("‚úÖ Operation traced with OpenTelemetry")
                print(f"   Service: {self.observability.config.get('service_name')}")
                print("   Traces sent to configured endpoint")
        else:
            print("‚ö†Ô∏è  OpenTelemetry not configured")


async def main():
    """
    Demonstrate realistic AI coding assistant using hybrid file operations.
    """
    
    print("ü§ñ AI CODE ASSISTANT - HYBRID DEMONSTRATION")
    print("=" * 60)
    
    # Create a realistic project structure
    with tempfile.TemporaryDirectory() as temp_dir:
        project_dir = Path(temp_dir) / "sample_project"
        project_dir.mkdir()
        
        # Create sample Python files
        (project_dir / "main.py").write_text("""#!/usr/bin/env python3
def main():
    print("Hello, World!")

if __name__ == "__main__":
    main()
""")
        
        (project_dir / "utils.py").write_text("""def helper_function(x, y):
    return x + y

class UtilityClass:
    def __init__(self, value):
        self.value = value
""")
        
        (project_dir / "config.py").write_text("""CONFIG = {
    "debug": True,
    "version": "1.0.0"
}
""")
        
        # Initialize AI assistant
        assistant = AICodeAssistant()
        
        # Demonstrate hybrid usage
        print(f"üìÅ Working with project: {project_dir}")
        
        # 1. Project analysis with AIDA (rich metadata)
        files = await assistant.process_project_with_aida(str(project_dir))
        
        # 2. Documentation generation with PydanticAI (clean functions)
        await assistant.generate_docs_with_pydantic(files, str(project_dir))
        
        # 3. External integration with MCP (universal compatibility)
        await assistant.integrate_with_external_via_mcp(str(project_dir))
        
        # 4. Observability demonstration
        await assistant.demonstrate_observability()
        
        # Show final project structure
        print("\nüìÇ FINAL PROJECT STRUCTURE")
        print("-" * 40)
        
        file_tool = FileOperationsTool()
        result = await file_tool.execute(
            operation="list_files",
            path=str(project_dir),
            recursive=True
        )
        
        for file_info in result.result['files']:
            print(f"   {file_info['name']} ({file_info['size']} bytes)")
        
        print(f"\n‚ú® Total files created: {result.result['total_files']}")
    
    print("\nüéØ REAL-WORLD BENEFITS DEMONSTRATED")
    print("=" * 60)
    print("‚úÖ AIDA: Rich metadata for internal analysis")
    print("‚úÖ PydanticAI: Clean functions for AI operations")  
    print("‚úÖ MCP: External system integration")
    print("‚úÖ Observability: Production monitoring")
    print("‚úÖ All working together in one application!")


if __name__ == "__main__":
    asyncio.run(main())